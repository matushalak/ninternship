import numpy as np
from scipy.special import gammaln
import matplotlib.pyplot as plt
from joblib import cpu_count, delayed, Parallel
import MODEL.adEx_models as adEx
from MODEL.adEx_utils import run_experiment
from typing import Callable

# OPTIMIZATION
from scipy.optimize import differential_evolution
import nevergrad as ng

import time
from tqdm import tqdm

from MODEL import PYDATA
import os

### --- Optimizer utils ---
def loss_func(ypred:np.ndarray, y:np.ndarray,
              EPSILON:float = 1e-6, FIRING_penalty:float = .75
              )->float:
    '''
    # NEGATIVE POISSON LOG-LIKELIHOOD + SPIKING INCENTIVE
    Treat the spike counts (in 66ms calcium imaging bins) generated by our model as 
    Poisson distributed and calculate poisson log likelihood:
    ### Poisson likelihood: P(k|λ) = (λ^k * e^(-λ)) / k!
    ### Log-likelihood: LL = k*log(λ) - λ - log(k!)
    
    #### Where:
    - k = observed spike counts (target data y)
    - λ = predicted spike rate (model output ypred)
    '''
    assert ypred.shape == y.shape, 'Spike counts must be sampled at same time resolution'
    ## 1) Poisson Log-likelihood part
    # cast to float to allow taking logs
    observed = y.astype(float)
    predicted = ypred.astype(float)
    # Add small epsilon to 0s to prevent ln(0) undefined
    np.maximum(observed, EPSILON, out = observed)
    np.maximum(predicted, EPSILON, out = predicted)
    
    # Calculate Poisson log likelihood at each bin (vectorized)
    # log(k!) = gammaln(k+1)
    LLs = (observed * np.log(predicted)) - predicted - gammaln(observed+1)
    # Total log likelihood
    LL = np.sum(LLs)
    
    # If perfectly predicted
    LLoptimal = np.sum((observed * np.log(observed)) - observed - gammaln(observed+1))
    
    # Normalized negative LL : 0 is perfect
    nLLnorm = -(LL - LLoptimal) / abs(LLoptimal)

    ## 2) Spike Rate difference
    if np.sum(predicted) == 0:
        spike_rate_penalty = 10000
    else:
        spike_rate_penalty = (np.sum(predicted) - np.sum(observed))**2
    
    # LL : spike rate penalizations
    LLpenaltyWeight = 1 #- FIRING_penalty
    
    return (LLpenaltyWeight * nLLnorm) + (FIRING_penalty * spike_rate_penalty)


class Parameters:
    ''''
    Define parameter bounds for CadEx model + synaptic weights
    9 intrinsic model parameters
    ----------------------------
    C      = (30, 300)
    gL     = (1.5, 15)
    EL     = (-70, -59)
    VT     = (-60, -42)
    DeltaT = (0.6, 6)
    tauw   = (16, 720)
    a      = (-12, 80)
    Vreset = (-80, -40) 
    b      = (0, 400)
    gs    = (0, 1) # overall synaptic conductance
    
    N synaptic weights
    ----------------------------
    A      = synaptic weight (-1, 1)
        - 1 inhibitory, +1 excitatory
        range verified with dfSCALER = 10: 
            if +1 totally epilepsic, spiking all the time
            if -1 no spikes just extremely hyperpolarized
    '''
    # Intrinsic parameters (9 parameters)
    intrinsic_bounds = {
        'C': (30, 300),          # Capacitance (pF)
        'gL': (1.5, 15),         # Leak conductance (nS)  
        'EL': (-70, -59),        # Leak reversal (mV)
        'VT': (-60, -42),        # Threshold voltage (mV)
        'DeltaT': (0.6, 6),      # Slope factor (mV)
        'tauw': (16, 720),       # Adaptation time constant (ms)
        'a': (-12, 80),          # Subthreshold adaptation (nS)
        'gs': (0, 1),            # Synaptic scaling factor
        # Reset parameters
        'Vreset': (-80, -40),    # Reset voltage (mV)
        'b': (0, 400),           # Spike-triggered adaptation (pA)
    }
    def __init__(self, ineuron:int, n_synapses:int):
        self.ineuron = ineuron
        self.n_synapses = n_synapses

        # Synaptic weights bounds (N)
        self.synaptic_bounds = [(-1, 1)] * n_synapses
        self.synaptic_bounds[ineuron] = (-1e-6,1e-6) # set own weight to 0

        self.param_bounds = list(Parameters.intrinsic_bounds.values()) + self.synaptic_bounds
    
    def get_bounds_array(self)->np.ndarray:
        return np.array(self.param_bounds)
    
    @classmethod
    def params_to_dict(self, params:np.ndarray)->dict:
        intrinsic_keys = list(Parameters.intrinsic_bounds.keys())
        paramDict = {k:params[i] for i, k in enumerate(intrinsic_keys)}
        paramDict['synaptic_weights'] = params[len(intrinsic_keys):]
        return paramDict
    
    def dict_to_params(self, model_params:dict, adjM:np.ndarray
                       ) -> np.ndarray:
        return np.array(list(model_params.keys()) + adjM.tolist())


class Optimizer:
    """
    Optimizer class for CadEx parameter fitting
    new approaches can be added as methods

    objective : Callable (x) takes parameters vector (as specified in )
    """
    def __init__(self, bounds:Parameters, objective_fun:Callable):
        self.Params = bounds
        self.bounds = bounds.get_bounds_array()
        self.objective_fun = objective_fun
        self.optim_history = []
    
    def callback_(self, xk, convergence=None):
        """
        Track optimization progress
        
        Parameters:
        -----------
        xk : array_like
            Current best solution vector
        convergence : float, optional
            Convergence measure (not always provided)
        """
        self.iteration_count += 1
        
        try:
            current_loss = self.objective_fun(xk)
            self.optim_history.append({
                'iteration': self.iteration_count,
                'loss': current_loss,
                'parameters': xk.copy(),
                'convergence': convergence
            })
            
            print(f"Generation {self.iteration_count}: Loss = {current_loss:.4f}", flush=True)
            
        except Exception as e:
            print(f"Error in callback: {e}", flush=True)
            
        return False  # Continue optimization
    
    def random_initialization(self, n_candidates=5):
        """
        Generate starting points within bounds
        TODO: 
        make this start within known firing ranges
        """
        candidates = []
        
        for _ in range(n_candidates):
            candidate = []
            for (low, high) in self.bounds:
                candidate.append(np.random.uniform(low, high))
            candidates.append(np.array(candidate))
            
        return candidates
    
    def differential_evolution_optimize(self, maxiter=1000, popsize=15, 
                                     seed=None, polish=True):
        """
        Differential Evolution - Great for global optimization
        Recommended as first choice for neural model fitting
        """
        print("Starting Differential Evolution optimization...")
        print(f"Population size multiplier: {popsize}")
        print(f"Max iterations: {maxiter}")
        
        start_time = time.time()
        
        # Reset tracking
        self.optim_history = []
        self.iteration_count = 0
        
        try:
            result = differential_evolution(
                func=self.objective_fun,
                bounds=self.bounds,
                maxiter=maxiter,
                popsize=popsize,
                seed=seed,
                polish=polish,
                callback=self.callback_,
                # disp=True,
            )
            
            optimization_time = time.time() - start_time
            print(f"DE completed in {optimization_time:.2f} seconds")
            print(f"Success: {result.success}")
            print(f"Message: {result.message}")
            print(f"Function evaluations: {result.nfev}")
            print(f"Final loss: {result.fun:.6f}")
            
            return result
            
        except Exception as e:
            print(f"Optimization failed with error: {e}")
            optimization_time = time.time() - start_time
            print(f"Failed after {optimization_time:.2f} seconds")
            raise



def create_objective_function(adExModel:adEx, Tmax:float,
                              dt:float, Iapp:np.ndarray, 
                              eval_arr:np.ndarray, 
                              MLspikeMaxSpikes:int,
                              ineuron:int, ts:np.ndarray
                              )->Callable:
    """
    Create objective function that wraps run_experiment for CadEx model
    """
    def objective(param_vector)->float:
        # print('Evaluating: ', param_vector[:10], flush=True)
        # Convert parameter vector to model parameters
        model_params:dict = Parameters.params_to_dict(params=param_vector)
        adjM = np.ascontiguousarray(model_params['synaptic_weights'])
        model_params.pop('synaptic_weights', None)
        model_params['Vpeak'] = 0
        
        # Run AdEx simulation
        pred_spts_ms = run_experiment(adExModel= adExModel,
                                    Tmax=Tmax, dt = dt,
                                    model_params=model_params,
                                    Iapp=Iapp, 
                                    adjM=adjM,
                                    evaluate=True,
                                    ineuron=ineuron,
                                    plot=False,
                                    ts = ts)
        ypred = bin_spikes(spts_ms=pred_spts_ms, nbins=eval_arr.size, Tmax_ms=Tmax,
                           maxcount=MLspikeMaxSpikes)
        
        L = loss_func(ypred=ypred, y = eval_arr)
        # print(L, flush=True)
        return L
    
    return objective


def create_debug_objective_function(adExModel, Tmax, dt, Iapp, eval_arr, 
                                   MLspikeMaxSpikes, ineuron, ts):
    """
    Debug version of objective function to track what's happening
    """
    call_count = 0
    loss_cache = {}
    
    def objective(param_vector):
        nonlocal call_count, loss_cache
        call_count += 1
        
        # Create a hash of the parameter vector to check for duplicates
        param_hash = hash(tuple(np.round(param_vector, 8)))
        
        print(f"\n=== Objective Call #{call_count} ===")
        print(f"Param hash: {param_hash}")
        print(f"First 5 params: {param_vector[:5]}")
        print(f"Last 5 params: {param_vector[-5:]}")
        
        # Convert parameter vector to model parameters
        try:
            model_params = Parameters.params_to_dict(params=param_vector)
            print(f"Model params keys: {list(model_params.keys())}")
            print(f"Intrinsic params: {[(k,v) for k,v in model_params.items() if k != 'synaptic_weights']}")
            print(f"Synaptic weights shape: {np.array(model_params['synaptic_weights']).shape}")
            print(f"Synaptic weights (first 5): {model_params['synaptic_weights'][:5]}")
            
            adjM = np.ascontiguousarray(model_params['synaptic_weights'])
            model_params.pop('synaptic_weights', None)
            model_params['Vpeak'] = 0
            
        except Exception as e:
            print(f"ERROR in parameter conversion: {e}")
            return 1e10
        
        # Run AdEx simulation
        try:
            print("Running experiment...")
            pred_spts_ms = run_experiment(
                adExModel=adExModel,
                Tmax=Tmax, dt=dt,
                model_params=model_params,
                Iapp=Iapp, 
                adjM=adjM,
                evaluate=True,
                ineuron=ineuron,
                plot=False,
                ts=ts
            )
            
            print(f"Simulation returned {len(pred_spts_ms)} spikes")
            print(f"Spike times (first 10): {pred_spts_ms[:10] if len(pred_spts_ms) > 0 else 'No spikes'}")
            
        except Exception as e:
            print(f"ERROR in run_experiment: {e}")
            import traceback
            traceback.print_exc()
            return 1e10
        
        # Bin spikes
        try:
            ypred = bin_spikes(spts_ms=pred_spts_ms, nbins=eval_arr.size, 
                              Tmax_ms=Tmax, maxcount=MLspikeMaxSpikes)
            
            print(f"Binned spikes shape: {ypred.shape}")
            print(f"Binned spikes sum: {np.sum(ypred)}")
            print(f"Binned spikes (first 10): {ypred[:10]}")
            print(f"Target spikes sum: {np.sum(eval_arr)}")
            print(f"Target spikes (first 10): {eval_arr[:10]}")
            
        except Exception as e:
            print(f"ERROR in bin_spikes: {e}")
            return 1e10
        
        # Calculate loss
        try:
            L = loss_func(ypred=ypred, y=eval_arr)
            print(f"Calculated loss: {L}")
            
            # Check if we've seen this loss before
            if L in loss_cache:
                print(f"WARNING: This exact loss ({L}) was seen before!")
                print(f"Previous params: {loss_cache[L][:5]}...")
                print(f"Current params:  {param_vector[:5]}...")
            else:
                loss_cache[L] = param_vector.copy()
            
            return L
            
        except Exception as e:
            print(f"ERROR in loss_func: {e}")
            import traceback
            traceback.print_exc()
            return 1e10
    
    return objective

# Test function to run multiple random evaluations
def test_objective_randomness(objective_func, bounds, n_tests=10):
    """Test objective function with random parameters"""
    print(f"\n=== Testing {n_tests} Random Parameter Sets ===")
    
    losses = []
    param_sets = []
    
    for i in range(n_tests):
        # Generate random parameters
        bounds_array = bounds.get_bounds_array()
        test_params = []
        for (low, high) in bounds_array:
            test_params.append(np.random.uniform(low, high))
        test_params = np.array(test_params)
        
        print(f"\n--- Test {i+1}/{n_tests} ---")
        loss = objective_func(test_params)
        
        losses.append(loss)
        param_sets.append(test_params.copy())
        
        print(f"Test {i+1} loss: {loss}")
    
    print(f"\n=== Summary ===")
    print(f"Unique losses: {len(set(losses))}")
    print(f"All losses: {losses}")
    print(f"Most common loss: {max(set(losses), key=losses.count)}")
    print(f"Count of most common: {losses.count(max(set(losses), key=losses.count))}")
    
    return losses, param_sets

#%%
def __runWRAP__(ineuron:int, 
                model:adEx, 
                INPUT_highHZ:np.ndarray,
                adjROW:np.ndarray,
                eval_arr:np.ndarray | None,
                model_params:dict,
                MODELts:np.ndarray,
                Tmaxmodel:float, DTmodel:float, 
                plot:bool,
                MLspikeMaxSpikes:int = 3):
    '''
    Wrapper for running parameter fitting for synaptic CadEx in a 
    parallelized manner using joblib

    or also just for plotting and exploring (synaptic) CadEx
    '''
    adjROW[ineuron] = 0
    evaluate = isinstance(eval_arr, np.ndarray)
    
    # Run optimization
    if evaluate:
        # Optimization setup
        BOUNDS = Parameters(ineuron=ineuron, n_synapses=adjROW.size)
        OBJECTIVE:Callable = create_objective_function(
            adExModel= model, Tmax=Tmaxmodel, 
            dt = DTmodel, Iapp=INPUT_highHZ, 
            eval_arr=eval_arr,
            MLspikeMaxSpikes=MLspikeMaxSpikes,
            ineuron=ineuron, ts = MODELts)
        OPTIMIZER = Optimizer(bounds=BOUNDS, objective_fun=OBJECTIVE)
        
        # test_objective_randomness(OBJECTIVE, bounds=BOUNDS, n_tests=50)
        # Method 1: Differential Evolution (recommended first try)
        print("=== Differential Evolution ===")
        de_result = OPTIMIZER.differential_evolution_optimize(maxiter=2, popsize=5)
        
        # # Extract best parameters
        # best_params = BOUNDS.params_to_dict(de_result.x)
        # print(f"\nBest loss: {de_result.fun:.4f}")
        # print("Best parameters:")
        # for name, value in best_params.items():
        #     if name != 'synaptic_weights':
        #         print(f"  {name}: {value:.3f}")
        # print(f"  Synaptic weights: {len(best_params['synaptic_weights'])} values")
        
        # return de_result, OPTIMIZER.optim_history

    # Simply run experiment on one parameter set
    else:
        pred_spts_ms = run_experiment(adExModel= model,
                                    Tmax=Tmaxmodel, dt = DTmodel,
                                    model_params=model_params,
                                    Iapp=INPUT_highHZ, 
                                    adjM=adjROW,
                                    evaluate=evaluate,
                                    ineuron=ineuron,
                                    plot=plot,
                                    ts = MODELts)


### --- Other model utils ---
def bin_spikes(spts_ms:np.ndarray, nbins:int, Tmax_ms:float,
               maxcount:int)->np.ndarray:
    """
    Bin high-res spiketimes into designated number of bins
    """
    bin_edges = np.linspace(0,Tmax_ms, nbins+1)
    spike_counts, _ = np.histogram(spts_ms, bins = bin_edges)
    return np.clip(spike_counts, 0,maxcount)


def upsampling_worker(sigBATCH:np.ndarray, MODELts:np.ndarray,
                      batchSize:int,
                      SIGsize:float, MODELsize:int,
                      gaussSD:float, 
                      bindelaysBATCH:np.ndarray, additionalMSoffset:float,
                      ibatch:int,
                      ):
    pid = os.getpid()
    print(f"[upsampling_worker STARTED, PID={pid}, batchSize={batchSize}]", flush=True)
    BATCH = np.zeros((MODELsize, batchSize), dtype=float, order = 'C')
    MODELdownsampledTS = np.linspace(MODELts[0], MODELts[-1], SIGsize)
    for ni in tqdm(range(batchSize), position=ibatch):
        # Linear interpolation to get higher sampling rate
        out = np.interp(x=MODELts, xp = MODELdownsampledTS, fp = sigBATCH[:,ni])
        # Convolve with gaussian to smooth over linear interpolation artifacts
        symmgaussrange = np.linspace(-MODELsize//2, MODELsize//2, MODELsize)
        gaussian = np.exp(-(symmgaussrange/gaussSD)**2/2)
        gaussian = gaussian[gaussian > 0]
        out = np.convolve(out, gaussian, mode='same')
        # 0 pad from left to shift by few ms (first to correct for imaging offset)
        # + to allow for some "causality" in which signal came first
        lag = round(bindelaysBATCH[ni] + additionalMSoffset)
        out = np.roll(out, shift = lag)
        out[:lag] = 0
        BATCH[:,ni] = out
        # print('Neuron w lag: ',lag, 'done', flush=True)
    return BATCH

def upsample_memory_optimized(sig: np.ndarray,
                             MODELts: np.ndarray,
                             MODELsize: int,
                             SIGsize: int,
                             ITERneuron: np.ndarray,
                             msdelays: np.ndarray,
                             gaussSD: float = 20,
                             additionalMSoffset: float = 5,
                             ) -> tuple[np.ndarray, np.ndarray]:
    
    # Force single-threaded NumPy to avoid conflicts
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'
    os.environ['OMP_NUM_THREADS'] = '1'
    
    bindelays = np.round(msdelays)
    
    # Use fewer workers for memory-intensive tasks
    n_workers = min(cpu_count() // 2, 8)
    batches = np.array_split(ITERneuron, n_workers)
    
    print(f"Memory-optimized version using {n_workers} workers")
    
    worker_args = [
        [sig[:, batch].copy(),  # Make explicit copies to avoid sharing issues
         MODELts.copy(),
         batch.size,
         SIGsize, MODELsize,
         gaussSD,
         bindelays[batch].copy(), additionalMSoffset,
         ibatch
        ]
        for ibatch, batch in enumerate(batches)
    ]
    
    # Try different multiprocessing backends
    for backend in ['loky', 'threading', 'multiprocessing']:
        try:
            print(f"Trying backend: {backend}")
            outList = Parallel(n_jobs=n_workers, verbose=10, backend=backend)(
                delayed(upsampling_worker)(*wa) for wa in worker_args
            )
            print(f"Success with {backend} backend!")
            break
        except Exception as e:
            print(f"Failed with {backend}: {e}")
            continue
    else:
        print("All backends failed, falling back to sequential processing")
        # single core also good for debugging
        outList = [upsampling_worker(*wa) for wa in worker_args]
    
    return np.column_stack(outList)