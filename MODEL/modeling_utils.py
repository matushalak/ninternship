import numpy as np
from scipy.special import gammaln
import matplotlib.pyplot as plt
from joblib import cpu_count, delayed, Parallel
import MODEL.adEx_models as adEx
from MODEL.adEx_utils import run_experiment
from typing import Callable

# OPTIMIZATION
from scipy.optimize import minimize, differential_evolution
from scipy.stats import truncnorm

import time
from tqdm import tqdm

from MODEL import PYDATA
import os

### --- Optimizer utils ---
def loss_func(ypred:np.ndarray, y:np.ndarray,
              EPSILON:float = 1e-6
              )->float:
    '''
    # NEGATIVE POISSON LOG-LIKELIHOOD
    Because we don't have ms resolution can't use
    Coincidence factor, used by Clopath, Jolivet, Gerstener et al.

    Instead, treat the spike counts generated by our model as 
    Poisson distributed and calculate poisson log likelihood:
        PLL = k*log(λ) - λ - log(k!)
        k = predicted spike counts, lambda = observed spike counts
    '''
    assert ypred.shape == y.shape, 'Spike counts must be sampled at same time resolution'
    # cast to float to allow taking logs
    observed = y.astype(float)
    predicted = ypred.astype(float)
    # Add small epsilon to 0s to prevent ln(0) undefined
    np.maximum(observed, EPSILON, out = observed)
    np.maximum(predicted, EPSILON, out = predicted)
    
    # Calculate Poisson log likelihood at each bin (vectorized)
    # log(k!) = gammaln(k+1)
    LLs = (predicted * np.log(observed)) - observed - gammaln(predicted+1)
    # Total log likelihood
    LL = np.sum(LLs)
    # Return negative LogLikelihood (for minimization optimizers)
    return -LL


class Parameters:
    ''''
    Define parameter bounds for CadEx model + synaptic weights
    9 intrinsic model parameters
    ----------------------------
    C      = (30, 300)
    gL     = (1.5, 15)
    EL     = (-70, -59)
    VT     = (-60, -42)
    DeltaT = (0.6, 6)
    tauw   = (16, 720)
    a      = (-12, 80)
    Vreset = (-80, -40) 
    b      = (0, 400)
    gs    = (0, 1) # overall synaptic conductance
    
    N synaptic weights
    ----------------------------
    A      = synaptic weight (-1, 1)
        - 1 inhibitory, +1 excitatory
        range verified with dfSCALER = 10: 
            if +1 totally epilepsic, spiking all the time
            if -1 no spikes just extremely hyperpolarized
    '''
    # Intrinsic parameters (9 parameters)
    intrinsic_bounds = {
        'C': (30, 300),          # Capacitance (pF)
        'gL': (1.5, 15),         # Leak conductance (nS)  
        'EL': (-70, -59),        # Leak reversal (mV)
        'VT': (-60, -42),        # Threshold voltage (mV)
        'DeltaT': (0.6, 6),      # Slope factor (mV)
        'tauw': (16, 720),       # Adaptation time constant (ms)
        'a': (-12, 80),          # Subthreshold adaptation (nS)
        'gs': (0, 1),            # Synaptic scaling factor
        # Reset parameters
        'Vreset': (-80, -40),    # Reset voltage (mV)
        'b': (0, 400),           # Spike-triggered adaptation (pA)
    }
    def __init__(self, ineuron:int, n_synapses:int):
        self.ineuron = ineuron
        self.n_synapses = n_synapses

        # Synaptic weights bounds (N)
        self.synaptic_bounds = [(-1, 1)] * n_synapses
        self.synaptic_bounds[ineuron] = (-1e-6,1e-6) # set own weight to 0

        self.param_bounds = list(Parameters.intrinsic_bounds.values()) + self.synaptic_bounds
    
    def get_bounds_array(self)->np.ndarray:
        return np.array(self.param_bounds)
    
    @classmethod
    def params_to_dict(self, params:np.ndarray)->dict:
        intrinsic_keys = list(Parameters.intrinsic_bounds.keys())
        paramDict = {k:params[i] for i, k in enumerate(intrinsic_keys)}
        paramDict['synaptic_weights'] = params[len(intrinsic_keys):]
        return paramDict
    
    def dict_to_params(self, model_params:dict, adjM:np.ndarray
                       ) -> np.ndarray:
        return np.array(list(model_params.keys()) + adjM.tolist())


class Optimizer:
    """
    Optimizer class for CadEx parameter fitting
    new approaches can be added as methods

    objective : Callable (x) takes parameters vector (as specified in )
    """
    def __init__(self, bounds:Parameters, objective_fun:Callable):
        self.Params = bounds
        self.bounds = bounds.get_bounds_array()
        self.objective_fun = objective_fun
        self.optim_history = []
    
    def callback_(self, xk, convergence=None):
        """
        Track optimization progress
        
        Parameters:
        -----------
        xk : array_like
            Current best solution vector
        convergence : float, optional
            Convergence measure (not always provided)
        """
        self.iteration_count += 1
        
        try:
            current_loss = self.objective_fun(xk)
            self.optim_history.append({
                'iteration': self.iteration_count,
                'loss': current_loss,
                'parameters': xk.copy(),
                'convergence': convergence
            })
            
            print(f"Generation {self.iteration_count}: Loss = {current_loss:.4f}", flush=True)
            
        except Exception as e:
            print(f"Error in callback: {e}", flush=True)
            
        return False  # Continue optimization
    
    def random_initialization(self, n_candidates=5):
        """
        Generate starting points within bounds
        TODO: 
        make this start within known firing ranges
        """
        candidates = []
        
        for _ in range(n_candidates):
            candidate = []
            for (low, high) in self.bounds:
                candidate.append(np.random.uniform(low, high))
            candidates.append(np.array(candidate))
            
        return candidates
    
    def differential_evolution_optimize(self, maxiter=1000, popsize=15, 
                                     seed=None, polish=True):
        """
        Differential Evolution - Great for global optimization
        Recommended as first choice for neural model fitting
        """
        print("Starting Differential Evolution optimization...")
        print(f"Population size multiplier: {popsize}")
        print(f"Max iterations: {maxiter}")
        
        start_time = time.time()
        
        # Reset tracking
        self.optim_history = []
        self.iteration_count = 0
        
        breakpoint()
        try:
            result = differential_evolution(
                func=self.objective_fun,
                bounds=self.bounds,
                maxiter=maxiter,
                popsize=popsize,
                seed=seed,
                polish=polish,
                callback=self.callback_,
                disp=True,
            )
            
            optimization_time = time.time() - start_time
            print(f"DE completed in {optimization_time:.2f} seconds")
            print(f"Success: {result.success}")
            print(f"Message: {result.message}")
            print(f"Function evaluations: {result.nfev}")
            print(f"Final loss: {result.fun:.6f}")
            
            return result
            
        except Exception as e:
            print(f"Optimization failed with error: {e}")
            optimization_time = time.time() - start_time
            print(f"Failed after {optimization_time:.2f} seconds")
            raise



def create_objective_function(adExModel:adEx, Tmax:float,
                              dt:float, Iapp:np.ndarray, 
                              eval_arr:np.ndarray, 
                              MLspikeMaxSpikes:int,
                              ineuron:int, ts:np.ndarray
                              )->Callable:
    """
    Create objective function that wraps run_experiment for CadEx model
    """
    def objective(param_vector)->float:
        # print('Evaluating: ', param_vector[:10], flush=True)
        # Convert parameter vector to model parameters
        model_params:dict = Parameters.params_to_dict(params=param_vector)
        adjM = np.ascontiguousarray(model_params['synaptic_weights'])
        model_params.pop('synaptic_weights', None)
        model_params['Vpeak'] = 0
        
        # Run AdEx simulation
        pred_spts_ms = run_experiment(adExModel= adExModel,
                                    Tmax=Tmax, dt = dt,
                                    model_params=model_params,
                                    Iapp=Iapp, 
                                    adjM=adjM,
                                    evaluate=True,
                                    ineuron=ineuron,
                                    plot=False,
                                    ts = ts)
        ypred = bin_spikes(spts_ms=pred_spts_ms, nbins=eval_arr.size, Tmax_ms=Tmax,
                           maxcount=MLspikeMaxSpikes)
        
        L = loss_func(ypred=ypred, y = eval_arr)
        # print(L, flush=True)
        return L
    
    return objective

#%%
def __runWRAP__(ineuron:int, 
                model:adEx, 
                INPUT_highHZ:np.ndarray,
                adjROW:np.ndarray,
                eval_arr:np.ndarray | None,
                model_params:dict,
                MODELts:np.ndarray,
                Tmaxmodel:float, DTmodel:float, 
                plot:bool,
                MLspikeMaxSpikes:int = 3):
    '''
    Wrapper for running parameter fitting for synaptic CadEx in a 
    parallelized manner using joblib

    or also just for plotting and exploring (synaptic) CadEx
    '''
    adjROW[ineuron] = 0
    evaluate = isinstance(eval_arr, np.ndarray)
    
    # Run optimization
    if evaluate:
        # Optimization setup
        BOUNDS = Parameters(ineuron=ineuron, n_synapses=adjROW.size)
        OBJECTIVE:Callable = create_objective_function(
            adExModel= model, Tmax=Tmaxmodel, 
            dt = DTmodel, Iapp=INPUT_highHZ, 
            eval_arr=eval_arr,
            MLspikeMaxSpikes=MLspikeMaxSpikes,
            ineuron=ineuron, ts = MODELts)
        OPTIMIZER = Optimizer(bounds=BOUNDS, objective_fun=OBJECTIVE)
        
        # Method 1: Differential Evolution (recommended first try)
        print("=== Differential Evolution ===")
        de_result = OPTIMIZER.differential_evolution_optimize(maxiter=10, popsize=5)
        
        # Extract best parameters
        best_params = BOUNDS.params_to_dict(de_result.x)
        print(f"\nBest loss: {de_result.fun:.4f}")
        print("Best parameters:")
        for name, value in best_params.items():
            if name != 'synaptic_weights':
                print(f"  {name}: {value:.3f}")
        print(f"  Synaptic weights: {len(best_params['synaptic_weights'])} values")
        
        return de_result, OPTIMIZER.optim_history

    # Simply run experiment on one parameter set
    else:
        pred_spts_ms = run_experiment(adExModel= model,
                                    Tmax=Tmaxmodel, dt = DTmodel,
                                    model_params=model_params,
                                    Iapp=INPUT_highHZ, 
                                    adjM=adjROW,
                                    evaluate=evaluate,
                                    ineuron=ineuron,
                                    plot=plot,
                                    ts = MODELts)


### --- Other model utils ---
def bin_spikes(spts_ms:np.ndarray, nbins:int, Tmax_ms:float,
               maxcount:int)->np.ndarray:
    """
    Bin high-res spiketimes into designated number of bins
    """
    bin_edges = np.linspace(0,Tmax_ms, nbins+1)
    spike_counts, _ = np.histogram(spts_ms, bins = bin_edges)
    return np.clip(spike_counts, 0,maxcount)


def upsampling_worker(sigBATCH:np.ndarray, MODELts:np.ndarray,
                      batchSize:int,
                      SIGsize:float, MODELsize:int,
                      gaussSD:float, 
                      bindelaysBATCH:np.ndarray, additionalMSoffset:float,
                      ibatch:int,
                      ):
    pid = os.getpid()
    print(f"[upsampling_worker STARTED, PID={pid}, batchSize={batchSize}]", flush=True)
    BATCH = np.zeros((MODELsize, batchSize), dtype=float, order = 'C')
    MODELdownsampledTS = np.linspace(MODELts[0], MODELts[-1], SIGsize)
    for ni in tqdm(range(batchSize), position=ibatch):
        # Linear interpolation to get higher sampling rate
        out = np.interp(x=MODELts, xp = MODELdownsampledTS, fp = sigBATCH[:,ni])
        # Convolve with gaussian to smooth over linear interpolation artifacts
        symmgaussrange = np.linspace(-MODELsize//2, MODELsize//2, MODELsize)
        gaussian = np.exp(-(symmgaussrange/gaussSD)**2/2)
        gaussian = gaussian[gaussian > 0]
        out = np.convolve(out, gaussian, mode='same')
        # 0 pad from left to shift by few ms (first to correct for imaging offset)
        # + to allow for some "causality" in which signal came first
        lag = round(bindelaysBATCH[ni] + additionalMSoffset)
        out = np.roll(out, shift = lag)
        out[:lag] = 0
        BATCH[:,ni] = out
        # print('Neuron w lag: ',lag, 'done', flush=True)
    return BATCH

def upsample_memory_optimized(sig: np.ndarray,
                             MODELts: np.ndarray,
                             MODELsize: int,
                             SIGsize: int,
                             ITERneuron: np.ndarray,
                             msdelays: np.ndarray,
                             gaussSD: float = 20,
                             additionalMSoffset: float = 5,
                             ) -> tuple[np.ndarray, np.ndarray]:
    
    # Force single-threaded NumPy to avoid conflicts
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'
    os.environ['OMP_NUM_THREADS'] = '1'
    
    bindelays = np.round(msdelays)
    
    # Use fewer workers for memory-intensive tasks
    n_workers = min(cpu_count() // 2, 8)
    batches = np.array_split(ITERneuron, n_workers)
    
    print(f"Memory-optimized version using {n_workers} workers")
    
    worker_args = [
        [sig[:, batch].copy(),  # Make explicit copies to avoid sharing issues
         MODELts.copy(),
         batch.size,
         SIGsize, MODELsize,
         gaussSD,
         bindelays[batch].copy(), additionalMSoffset,
         ibatch
        ]
        for ibatch, batch in enumerate(batches)
    ]
    
    # Try different multiprocessing backends
    for backend in ['loky', 'threading', 'multiprocessing']:
        try:
            print(f"Trying backend: {backend}")
            outList = Parallel(n_jobs=n_workers, verbose=10, backend=backend)(
                delayed(upsampling_worker)(*wa) for wa in worker_args
            )
            print(f"Success with {backend} backend!")
            break
        except Exception as e:
            print(f"Failed with {backend}: {e}")
            continue
    else:
        print("All backends failed, falling back to sequential processing")
        # single core also good for debugging
        outList = [upsampling_worker(*wa) for wa in worker_args]
    
    return np.column_stack(outList)