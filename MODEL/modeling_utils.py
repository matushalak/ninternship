import numpy as np
from scipy.special import gammaln
import matplotlib.pyplot as plt
from joblib import cpu_count, delayed, Parallel
import MODEL.adEx_models as adEx
from MODEL.adEx_utils import run_experiment, bin_spikes
from typing import Callable

# OPTIMIZATION
from scipy.optimize import differential_evolution
import nevergrad as ng

import time
from tqdm import tqdm

from MODEL import PYDATA
import os

### --- Optimizer utils ---
# TODO: consider also convolution and continuous optimization
# try correlation of w with each neuron’s dF/F
def loss_func(ypred:np.ndarray, y:np.ndarray,
              EPSILON:float = 1e-7, FIRING_penalty:float = .5
              )->float:
    '''
    # NEGATIVE POISSON LOG-LIKELIHOOD + SPIKING INCENTIVE
    Treat the spike counts (in 66ms calcium imaging bins) generated by our model as 
    Poisson distributed and calculate poisson log likelihood:
    ### Poisson likelihood: P(k|λ) = (λ^k * e^(-λ)) / k!
    ### Log-likelihood: LL = k*log(λ) - λ - log(k!)
    
    #### Where:
    - k = observed spike counts (target data y)
    - λ = predicted spike rate (model output ypred)
    '''
    assert ypred.shape == y.shape, 'Spike counts must be sampled at same time resolution'
    assert np.sum(y) !=0, 'Cannot fit the model if target vector has no spikes'
    if np.sum(ypred) == 0:
        spike_rate_penalty = 1e8
        # discourage no spiking
        return spike_rate_penalty
    N = y.size
    ## 1) Poisson Log-likelihood part
    # cast to float to allow taking logs
    observed = y.astype(float)
    predicted = ypred.astype(float)
    # Add small epsilon to 0s to prevent ln(0) undefined
    np.maximum(observed, EPSILON, out = observed)
    np.maximum(predicted, EPSILON, out = predicted)
    
    # only consider nonzero bins in Y
    # nonzero_bins = (y > 0)
    # observed = observed[nonzero_bins]
    # predicted = predicted[nonzero_bins]
    
    # Calculate Poisson log likelihood at each bin (vectorized)
    # log(k!) = gammaln(k+1)
    LLs = (observed * np.log(predicted)) - predicted - gammaln(observed+1)
    # Total log likelihood
    LL = np.sum(LLs)
    
    # If perfectly predicted
    LLoptimal = np.sum((observed * np.log(observed)) - observed - gammaln(observed+1))
    # Normalized negative LL : 0 is perfect
    nLLnorm = -(LL - LLoptimal)

    ## 2) Spike Rate difference
    NPREDspikes, NREALspikes = np.sum(ypred), np.sum(y)
    spike_rate_penalty = (NPREDspikes - NREALspikes)**2
    
    # LL : spike rate penalizations
    LLpenaltyWeight = 1
    print(f'{NPREDspikes} / {NREALspikes} spikes ',
          f'total loss: {(LLpenaltyWeight * nLLnorm) + (FIRING_penalty * spike_rate_penalty)} ',
          f'LL: {LL}, LLoptimal: {LLoptimal}, nLLnorm = {nLLnorm}', 
          flush=True)
    # return combined loss
    return (LLpenaltyWeight * nLLnorm) + (FIRING_penalty * spike_rate_penalty)


class Parameters:
    ''''
    Define parameter bounds for CadEx model + synaptic weights
    9 intrinsic model parameters
    ----------------------------
    C      = (30, 300)
    gL     = (1.5, 31)
    EL     = (-71, -59)
    VT     = (-60, -42)
    DeltaT = (0.6, 6)
    tauw   = (16, 720)
    a      = (-12, 80)
    Vreset = (-80, -40) 
    b      = (0, 400)
    gs    = (0, 1) # overall synaptic conductance
    
    N synaptic weights
    ----------------------------
    A      = synaptic weight (-1, 1)
        - 1 inhibitory, +1 excitatory
        range verified with dfSCALER = 10: 
            if +1 totally epilepsic, spiking all the time
            if -1 no spikes just extremely hyperpolarized
    '''
    # Intrinsic parameters (9 parameters)
    intrinsic_bounds = {
        'C': (30, 300),          # Capacitance (pF)
        'gL': (1.5, 31),         # Leak conductance (nS)  
        'EL': (-71, -57),        # Leak reversal (mV)
        'VT': (-60, -41.9),        # Threshold voltage (mV)
        'DeltaT': (0.6, 6),      # Slope factor (mV)
        'tauw': (15, 500),       # Adaptation time constant (ms)
        'a': (-30, 80),          # Subthreshold adaptation (nS)
        'gs': (0, 1),            # Synaptic scaling factor
        # Reset parameters
        'Vreset': (-80, -45),    # Reset voltage (mV)
        'b': (1e-5, 400),           # Spike-triggered adaptation (pA)
    }
    def __init__(self, ineuron:int, n_synapses:int):
        self.ineuron = ineuron
        self.n_synapses = n_synapses

        # Synaptic weights bounds (N)
        self.synaptic_bounds = [(-1, 1)] * n_synapses
        self.synaptic_bounds[ineuron] = (-1e-6,1e-6) # set own weight to 0

        self.param_bounds = list(Parameters.intrinsic_bounds.values()
                                 ) + self.synaptic_bounds
    
    def get_bounds_array(self)->np.ndarray:
        return np.array(self.param_bounds)
    
    @classmethod
    def params_to_dict(self, params:np.ndarray)->dict:
        intrinsic_keys = list(Parameters.intrinsic_bounds.keys())
        paramDict = {k:params[i] for i, k in enumerate(intrinsic_keys)}
        paramDict['synaptic_weights'] = params[len(intrinsic_keys):]
        return paramDict
    
    def dict_to_params(self, model_params:dict, adjM:np.ndarray
                       ) -> np.ndarray:
        return np.array(list(model_params.values()) 
                        + adjM.tolist()
                        )


class Optimizer:
    """
    Optimizer class for CadEx parameter fitting
    new approaches can be added as methods

    objective : Callable (x) takes parameters vector (as specified in )
    """
    def __init__(self, Params:Parameters, objective_fun:Callable, 
                 adjM:np.ndarray, model_params:dict):
        self.Params = Params
        self.bounds = Params.get_bounds_array()
        self.objective_fun = objective_fun
        self.optim_history = []
        # correlations adjM
        self.iniADJM = adjM
        # default initial model params
        model_params.pop('Vpeak', None)
        self.defaultParams = model_params
    
    def firing_patterns(self)->list[dict]:
        '''
        11 Initial "hot start" solutions based on adEx firing types
        identified in Table 1 Naud et al. (2008)
        '''
        keys = list(self.defaultParams.keys())
        assert 'Vpeak' not in keys

        # Table 1 Naud et al. (2008)
        values = {
        'C' : [59, 83, 104, 200, 200, 130, 200, 200, 200, 100, 100],     # pF
        'gL' : [2.9, 1.7, 4.3, 10, 12, 18, 10, 12, 12, 10, 12],     # nS
        'EL' : [-62, -59 , -65, -70, -70, -58, -58, -70, -70, -65, -60],    # mV
        'VT' : [-42,-56,-52,-50,-50,-50,-50,-50,-50,-50,-50],    # mV
        'DeltaT' : [3, 5.5, 0.8, 2,2,2,2,2,2,2,2],   # mV
        'tauw' : [16, 41, 88, 30, 300, 150, 120, 300, 300, 90, 130],  # ms
        'a' : [1.8, 2, -0.8, 2, 2, 4, 2, -10, -6, -10, -11],       # nS
        'gs' : [.8, .99, .99, .99, .99, .99, .75, .99, .99, .99, .99, .9], # overall synaptic conductance
        'Vreset' : [-54,-54,-53,-58,-58,-50,-46,-58,-58,-47,-48], # mV
        'b' : [61, 66, 65, 0.0001, 60, 120, 100, 0.0001, 0.0001, 30, 30],    # pA !!!!
        }

        firing_params = [{k:values[k][i] for k in keys}
                         for i in range(len(values['C']))]
        
        return firing_params


    def fit_with_nevergrad(self, generations:int = 20, popsize:int = 300):
        """
        Replace SciPy DE with Nevergrad CMA-ES.
        budget = total number of objective evaluations allowed.
                 (E.g. 200 means ~ 200 calls to objective().)
        """
        num_params = len(self.bounds)
        # default initial candidate
        default = self.Params.dict_to_params(self.defaultParams, self.iniADJM)

        # 11 other firing patterns identified in literature
        patterns = self.firing_patterns()

        # Initial guesses are patterns + default
        ini_guesses:list[np.ndarray] = [self.Params.dict_to_params(patt, self.iniADJM)
                                        for patt in patterns] + [default]
        
        # 1) Build a Nevergrad Parameter space with Box (continuous) bounds
        parametrization = ng.p.Array(shape=(num_params, ), 
                           lower=self.bounds[:,0], 
                           upper=self.bounds[:,1])
        
        parametrization.value = default
        
        # 2) Choose an optimizer; LOTS of room for improvement here
        CustomDE = ng.optimizers.DifferentialEvolution(
            initialization='LHS', crossover='random', popsize=popsize,
            multiobjective_adaptation=False, high_speed=True)
        
        optimizer = CustomDE(
            parametrization=parametrization,
            budget=generations,
            num_workers=popsize, 
        )
        counter = 0
        # 3) Main ask/tell loop through generations
        for gen in range(generations):
            #    We request one “candidate” at a time, evaluate it, then tell the optimizer.
            # candidate == individual solution
            for ind in range(popsize):
                # cand is a Nevergrad candidate
                # every 2 generations,
                # first len(ini_guesses) individuals are informed guesses
                # consisting of different firing patterns
                if gen % 2 == 0 and ind < len(ini_guesses):
                    # suggest takes in same input as our loss function
                    optimizer.suggest(ini_guesses[ind])
                
                # then next ask is the suggested one / or randomly generated one
                cand = optimizer.ask()
                # numpy array of length num_params       
                x = cand.value                       
                # 4) Evaluate the objective on x
                loss = self.objective_fun(x, gen, 
                                          True # optimize weights
                                          )
                counter += 1
                # 5) Tell the optimizer the loss
                optimizer.tell(cand, loss)

            # 6) Record best so far and print progress
            #    optimizer.provide_recommendation() returns the best seen candidate
            best = optimizer.provide_recommendation().value
            best_loss = self.objective_fun(best)

            self.optim_history.append({
                'generation': gen + 1,
                'loss':       best_loss,
                'params':     best.copy()
            })

            print(f"Gen {gen+1:3d}/{generations:3d}  Best loss = {best_loss:.6f}")
        print(counter)
        # 7) At the end, the final “recommendation” is our best estimate
        final_x = optimizer.provide_recommendation().value
        final_loss = self.objective_fun(final_x)
        print("NEVERGRAD done. Final loss =", final_loss)

        return final_x, final_loss
        

def create_objective_function(adExModel:adEx, Tmax:float,
                              dt:float, Iapp:np.ndarray, 
                              eval_arr:np.ndarray, 
                              MLspikeMaxSpikes:int,
                              ineuron:int, ts:np.ndarray,
                              ADJ:np.ndarray
                              )->Callable:
    """
    Create objective function that wraps run_experiment for CadEx model
    """
    def objective(param_vector, igen = 5, optimize_weights:bool = True)->float:
        # print('Evaluating: ', param_vector[:10], flush=True)
        # Convert parameter vector to model parameters
        model_params:dict = Parameters.params_to_dict(params=param_vector)
        A = ADJ
        if optimize_weights:
            adjM = np.ascontiguousarray(model_params['synaptic_weights'])
            model_params.pop('synaptic_weights', None)
        else:
            adjM = A
        model_params['Vpeak'] = 0
        
        # Run AdEx simulation
        pred_spts_ms = run_experiment(adExModel= adExModel,
                                    Tmax=Tmax, dt = dt,
                                    model_params=model_params,
                                    Iapp=Iapp, 
                                    adjM=adjM,
                                    evaluate=True,
                                    ineuron=ineuron,
                                    plot=False,
                                    ts = ts)
        ypred = bin_spikes(spts_ms=pred_spts_ms, nbins=eval_arr.size, Tmax_ms=Tmax,
                           maxcount=MLspikeMaxSpikes)
        
        L = loss_func(ypred=ypred, y = eval_arr, 
                    #   FIRING_penalty=np.exp(-.2*igen) # adaptive loss function (better without)
                      )
        return L
    
    return objective

def __runWRAP__(ineuron:int, 
                model:adEx, 
                INPUT_highHZ:np.ndarray,
                adjROW:np.ndarray,
                eval_arr:np.ndarray | None,
                model_params:dict,
                MODELts:np.ndarray,
                Tmaxmodel:float, DTmodel:float, 
                plot:bool,
                MLspikeMaxSpikes:int = 3):
    '''
    Wrapper for running parameter fitting for synaptic CadEx in a 
    parallelized manner using joblib

    or also just for plotting and exploring (synaptic) CadEx
    '''
    adjROW[ineuron] = 0
    evaluate = isinstance(eval_arr, np.ndarray)
    
    # Run optimization
    if evaluate:
        # Optimization setup
        BOUNDS = Parameters(ineuron=ineuron, n_synapses=adjROW.size)
        OBJECTIVE:Callable = create_objective_function(
            adExModel= model, Tmax=Tmaxmodel, 
            dt = DTmodel, Iapp=INPUT_highHZ, 
            eval_arr=eval_arr,
            MLspikeMaxSpikes=MLspikeMaxSpikes,
            ineuron=ineuron, ts = MODELts,
            ADJ=adjROW # if correlations hard-coded as the adjacency matrix
            )
        OPTIMIZER = Optimizer(Params=BOUNDS, objective_fun=OBJECTIVE,
                              adjM=adjROW, model_params=model_params)
        

        # Great for debugging and seeing what's going on
        # DEBUG_OBJECTIVE:Callable = create_debug_objective_function(
        #     adExModel= model, Tmax=Tmaxmodel, 
        #     dt = DTmodel, Iapp=INPUT_highHZ, 
        #     eval_arr=eval_arr,
        #     MLspikeMaxSpikes=MLspikeMaxSpikes,
        #     ineuron=ineuron, ts = MODELts)
        
        # test_objective_randomness(OPTIMIZER.objective_fun, bounds=BOUNDS, n_tests=50)
        
        print("=== NEVERGRAD CMA-ES Evolution ===")
        finalParam, finalLoss = OPTIMIZER.fit_with_nevergrad()

        if plot:
            _params = BOUNDS.params_to_dict(finalParam)
            # _ADJ = adjROW # when not optimizing weight
            _ADJ = _params.pop('synaptic_weights') # when optimizing weights
            _params['Vpeak'] = 0
            run_experiment(adExModel= model,
                            Tmax=Tmaxmodel, dt = DTmodel,
                            model_params=_params,
                            Iapp=INPUT_highHZ, 
                            adjM=_ADJ,
                            eval_array=eval_arr,
                            evaluate=evaluate,
                            ineuron=ineuron,
                            plot=plot,
                            ts = MODELts)
        

    # Simply run experiment on one parameter set
    else:
        pred_spts_ms = run_experiment(adExModel= model,
                                    Tmax=Tmaxmodel, dt = DTmodel,
                                    model_params=model_params,
                                    Iapp=INPUT_highHZ, 
                                    adjM=adjROW,
                                    evaluate=evaluate,
                                    ineuron=ineuron,
                                    plot=plot,
                                    ts = MODELts)


### --- Other model utils ---
def upsampling_worker(sigBATCH:np.ndarray, MODELts:np.ndarray,
                      batchSize:int,
                      SIGsize:float, MODELsize:int,
                      gaussSD:float, 
                      bindelaysBATCH:np.ndarray, additionalMSoffset:float,
                      ibatch:int,
                      ):
    pid = os.getpid()
    print(f"[upsampling_worker STARTED, PID={pid}, batchSize={batchSize}]", flush=True)
    BATCH = np.zeros((MODELsize, batchSize), dtype=float, order = 'C')
    MODELdownsampledTS = np.linspace(MODELts[0], MODELts[-1], SIGsize)
    for ni in tqdm(range(batchSize), position=ibatch):
        # Linear interpolation to get higher sampling rate
        out = np.interp(x=MODELts, xp = MODELdownsampledTS, fp = sigBATCH[:,ni])
        # Convolve with gaussian to smooth over linear interpolation artifacts
        symmgaussrange = np.linspace(-MODELsize//2, MODELsize//2, MODELsize)
        gaussian = np.exp(-(symmgaussrange/gaussSD)**2/2)
        gaussian = gaussian[gaussian > 0]
        out = np.convolve(out, gaussian, mode='same')
        # 0 pad from left to shift by few ms (first to correct for imaging offset)
        # + to allow for some "causality" in which signal came first
        lag = round(bindelaysBATCH[ni] + additionalMSoffset)
        out = np.roll(out, shift = lag)
        out[:lag] = 0
        BATCH[:,ni] = out
        # print('Neuron w lag: ',lag, 'done', flush=True)
    return BATCH

def upsample_memory_optimized(sig: np.ndarray,
                             MODELts: np.ndarray,
                             MODELsize: int,
                             SIGsize: int,
                             ITERneuron: np.ndarray,
                             msdelays: np.ndarray,
                             gaussSD: float = 20,
                             additionalMSoffset: float = 10,
                             ) -> tuple[np.ndarray, np.ndarray]:
    
    # Force single-threaded NumPy to avoid conflicts
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'
    os.environ['OMP_NUM_THREADS'] = '1'
    
    bindelays = np.round(msdelays)
    
    # Use fewer workers for memory-intensive tasks
    n_workers = min(cpu_count() // 2, 8)
    batches = np.array_split(ITERneuron, n_workers)
    
    print(f"Memory-optimized version using {n_workers} workers")
    
    worker_args = [
        [sig[:, batch].copy(),  # Make explicit copies to avoid sharing issues
         MODELts.copy(),
         batch.size,
         SIGsize, MODELsize,
         gaussSD,
         bindelays[batch].copy(), additionalMSoffset,
         ibatch
        ]
        for ibatch, batch in enumerate(batches)
    ]
    
    # Try different multiprocessing backends
    for backend in ['threading'
                    # , 'loky',  'multiprocessing'
                    ]:
        try:
            print(f"Trying backend: {backend}")
            outList = Parallel(n_jobs=n_workers, verbose=10, backend=backend)(
                delayed(upsampling_worker)(*wa) for wa in worker_args
            )
            print(f"Success with {backend} backend!")
            break
        except Exception as e:
            print(f"Failed with {backend}: {e}")
            continue
    else:
        print("All backends failed, falling back to sequential processing")
        # single core also good for debugging
        outList = [upsampling_worker(*wa) for wa in worker_args]
    
    return np.column_stack(outList)


## ---- DEBUGGING CORNER ----
def create_debug_objective_function(adExModel, Tmax, dt, Iapp, eval_arr, 
                                   MLspikeMaxSpikes, ineuron, ts):
    """
    Debug version of objective function to track what's happening
    """
    call_count = 0
    loss_cache = {}
    
    def objective(param_vector):
        nonlocal call_count, loss_cache
        call_count += 1
        
        # Create a hash of the parameter vector to check for duplicates
        param_hash = hash(tuple(np.round(param_vector, 8)))
        
        print(f"\n=== Objective Call #{call_count} ===")
        print(f"Param hash: {param_hash}")
        print(f"First 5 params: {param_vector[:5]}")
        print(f"Last 5 params: {param_vector[-5:]}")
        
        # Convert parameter vector to model parameters
        try:
            model_params = Parameters.params_to_dict(params=param_vector)
            print(f"Model params keys: {list(model_params.keys())}")
            print(f"Intrinsic params: {[(k,v) for k,v in model_params.items() if k != 'synaptic_weights']}")
            print(f"Synaptic weights shape: {np.array(model_params['synaptic_weights']).shape}")
            print(f"Synaptic weights (first 5): {model_params['synaptic_weights'][:5]}")
            
            adjM = np.ascontiguousarray(model_params['synaptic_weights'])
            model_params.pop('synaptic_weights', None)
            model_params['Vpeak'] = 0
            
        except Exception as e:
            print(f"ERROR in parameter conversion: {e}")
            return 1e10
        
        # Run AdEx simulation
        try:
            print("Running experiment...")
            pred_spts_ms = run_experiment(
                adExModel=adExModel,
                Tmax=Tmax, dt=dt,
                model_params=model_params,
                Iapp=Iapp, 
                adjM=adjM,
                evaluate=True,
                ineuron=ineuron,
                plot=False,
                ts=ts
            )
            
            print(f"Simulation returned {len(pred_spts_ms)} spikes")
            print(f"Spike times (first 10): {pred_spts_ms[:10] if len(pred_spts_ms) > 0 else 'No spikes'}")
            
        except Exception as e:
            print(f"ERROR in run_experiment: {e}")
            import traceback
            traceback.print_exc()
            return 1e10
        
        # Bin spikes
        try:
            ypred = bin_spikes(spts_ms=pred_spts_ms, nbins=eval_arr.size, 
                              Tmax_ms=Tmax, maxcount=MLspikeMaxSpikes)
            
            print(f"Binned spikes shape: {ypred.shape}")
            print(f"Binned spikes sum: {np.sum(ypred)}")
            print(f"Binned spikes (first 10): {ypred[:10]}")
            print(f"Target spikes sum: {np.sum(eval_arr)}")
            print(f"Target spikes (first 10): {eval_arr[:10]}")
            
        except Exception as e:
            print(f"ERROR in bin_spikes: {e}")
            return 1e10
        
        # Calculate loss
        try:
            L = loss_func(ypred=ypred, y=eval_arr)
            print(f"Calculated loss: {L}")
            
            # Check if we've seen this loss before
            if L in loss_cache:
                print(f"WARNING: This exact loss ({L}) was seen before!")
                print(f"Previous params: {loss_cache[L][:5]}...")
                print(f"Current params:  {param_vector[:5]}...")
            else:
                loss_cache[L] = param_vector.copy()
            
            return L
            
        except Exception as e:
            print(f"ERROR in loss_func: {e}")
            import traceback
            traceback.print_exc()
            return 1e10
    
    return objective

# Test function to run multiple random evaluations
def test_objective_randomness(objective_func, bounds, n_tests=10):
    """Test objective function with random parameters"""
    print(f"\n=== Testing {n_tests} Random Parameter Sets ===")
    
    losses = []
    param_sets = []
    
    for i in range(n_tests):
        # Generate random parameters
        bounds_array = bounds.get_bounds_array()
        test_params = []
        for (low, high) in bounds_array:
            test_params.append(np.random.uniform(low, high))
        test_params = np.array(test_params)
        
        print(f"\n--- Test {i+1}/{n_tests} ---")
        loss = objective_func(test_params)
        
        losses.append(loss)
        param_sets.append(test_params.copy())
        
        print(f"Test {i+1} loss: {loss}")
    
    print(f"\n=== Summary ===")
    print(f"Unique losses: {len(set(losses))}")
    print(f"All losses: {losses}")
    print(f"Most common loss: {max(set(losses), key=losses.count)}")
    print(f"Count of most common: {losses.count(max(set(losses), key=losses.count))}")
    
    return losses, param_sets
